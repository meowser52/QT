# Overview

Quantum GPT: LLM для генерации текста с использованием QML на GPT2-small.

Мы заменяем матрицы ключей, запросов и значений вариационными квантовыми схемами, эффективно сокращая количество обучаемых параметров

# Model card

Общее число параметров: 117M

Число квантовых параметров: 65k

# Benchmark results

| **Dataset** | LAMBADA 10k (first 10k symbols) |
|:-----------:|:-------------------------------:|
|  **Metric** |               PPL               |
|  **Score**  |              422.00             |


# Availible models

Текущая лучшая модель была обучена с использованием набора данных OpenWebText-100k на 30 эпохах.

![train plot](100k_loss.pdf)

Текущие требования: не менее 20 ГБ видеопамяти для обучения и 12 ГБ видеопамяти для вывода.

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F_H0je0UfVes"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n",
      "optax not installed, `optimizer` from jax backend cannot work\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pennylane as qml\n",
    "import tqml\n",
    "import torch\n",
    "import gc\n",
    "#from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torcheval.metrics.text import Perplexity\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.metrics as metrics\n",
    "from transformer_lens import HookedTransformer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ah-xV1q5f69l"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 5678\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "torch.cuda.manual_seed(seed=RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FWeV7j1Ef-Sy",
    "outputId": "d768e978-55ff-4ea9-a2de-0aa92b304b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqpZjp0eOLmq"
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-jef8DSPRQD",
    "outputId": "f007bd87-e787-4473-9eb9-46689df7eb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "reference_gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)\n",
    "gpt2_tokenizer = reference_gpt2.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_gpt2.state_dict()['blocks.0.attn.W_O'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzHAmtBpfaah",
    "outputId": "817e0253-e3c1-4aa1-b6db-03e9c7cdf898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256,    41, 17697, 30987,    11,   474, 17697, 30987,    11,   474,\n",
       "         17697,   477,   262,   835],\n",
       "        [50256,  8888,   314,   373,  6155,  1363,    11,   618,  6451, 50256,\n",
       "         50256, 50256, 50256, 50256]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_text = [\"Jingle bells, jingle bells, jingle all the way\", \"Today I was walking home, when suddenly\"]\n",
    "text_tokens = reference_gpt2.to_tokens(reference_text)\n",
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "P_fOP_uKbloL",
    "outputId": "4a14cac6-f8aa-4116-b814-f8ca97712a19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>Today I was walking home, when suddenly<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer.decode(text_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMPYJZO4OiCR",
    "outputId": "ec281050-5d76-40c7-8b1a-9c9453036c58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [220], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H416tK0Oh9Ms"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3U4O5UAfh_H4"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    #classical params\n",
    "    d_model: int = 768 #embedding size\n",
    "    layer_norm_eps: float = 1e-5\n",
    "    d_vocab: int = 50257\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 1024 #context length\n",
    "    n_heads: int = 12 #number of attention heads\n",
    "    n_layers: int = 12 #number of transformer blocks\n",
    "    dropout: float = 0.1\n",
    "    tying = False\n",
    "    #quantum params\n",
    "    query_depth: int = 2\n",
    "    key_depth: int = 2\n",
    "    value_depth: int = 2\n",
    "    q_device: str = \"lightning.qubit\"\n",
    "    speedy: bool = True\n",
    "    n_qubits: int = 8\n",
    "\n",
    "qgpt_cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eATEdf0P6Vg"
   },
   "source": [
    "# Embedding, MLP, Unembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WD2zhUlUQeHu"
   },
   "outputs": [],
   "source": [
    "class Embed(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.wte = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        self.wpe = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
    "\n",
    "        nn.init.normal_(self.wte, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.wpe, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        tok_emb = self.wte[tokens]\n",
    "        pos_emb = self.wpe[torch.arange(tokens.shape[1])]\n",
    "        embeddings = tok_emb + pos_emb\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lEBAnB2QVVLE"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.w_in = nn.Linear(cfg.d_model, 4 * cfg.d_model)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.w_out = nn.Linear(4 * cfg.d_model, cfg.d_model)\n",
    "        self.dropout = nn.Dropout(cfg.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.w_in(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.w_out(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SR_TS6R4XBzd"
   },
   "outputs": [],
   "source": [
    "class Unembed(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg, tying=None): #tying should be the W_E matrix\n",
    "        super().__init__()\n",
    "\n",
    "        self.unembed = nn.Linear(cfg.d_model, cfg.d_vocab)\n",
    "        if tying: self.unembed.weight = tying\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.unembed(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhG9998lgjL3"
   },
   "source": [
    "# Attention and transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D3-CU0x8gnI_"
   },
   "outputs": [],
   "source": [
    "import tqml.tqnet.speedy_layers\n",
    "\n",
    "\n",
    "class QAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.n_qubits = cfg.n_qubits\n",
    "        self.qkv_depth = (cfg.query_depth, cfg.key_depth, cfg.value_depth)\n",
    "        self.device = cfg.q_device\n",
    "        self.speedy = cfg.speedy\n",
    "\n",
    "        if self.cfg.d_model % self.n_qubits != 0:\n",
    "            raise ValueError(f\"in_features must be divisible by n_qubits, but got in_features={self.d_model} and n_qubits={self.n_qubits}\")\n",
    "        self.n_parallel = self.cfg.d_model // self.n_qubits #number of quantum heads\n",
    "\n",
    "        # init device\n",
    "        self.dev = qml.device(self.device, shots=None, wires=self.n_qubits)\n",
    "\n",
    "        # decide if we use tqml or pennylane\n",
    "        if self.speedy:\n",
    "            self.speedy_query = tqml.tqnet.speedy_layers.SpeedyPQN(cfg.d_model, cfg.n_qubits, self.qkv_depth[0])\n",
    "            self.speedy_key = tqml.tqnet.speedy_layers.SpeedyPQN(cfg.d_model, cfg.n_qubits, self.qkv_depth[1])\n",
    "            self.speedy_value = tqml.tqnet.speedy_layers.SpeedyPQN(cfg.d_model, cfg.n_qubits, self.qkv_depth[2])\n",
    "        else:\n",
    "            self.query_weights = nn.Parameter(torch.empty(self.n_parallel, self.qkv_depth[0], self.n_qubits))\n",
    "            self.key_weights = nn.Parameter(torch.empty(self.n_parallel, self.qkv_depth[1], self.n_qubits))\n",
    "            self.value_weights = nn.Parameter(torch.empty(self.n_parallel, self.qkv_depth[2], self.n_qubits))\n",
    "            self.reset_weights()\n",
    "            self.query_node = qml.QNode(self.queryCircuit, self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "            self.key_node = qml.QNode(self.keyCircuit, self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "            self.value_node = qml.QNode(self.valueCircuit, self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "        \n",
    "        #output projection is kept classical\n",
    "        #self.W_O = nn.Linear(self.cfg.d_model, self.cfg.d_model)\n",
    "        \n",
    "\n",
    "    def queryCircuit(self, inputs, weights, depth):\n",
    "\n",
    "        #quantum embedding\n",
    "        qml.AngleEmbedding(inputs, range(self.n_qubits))\n",
    "\n",
    "        #VQC\n",
    "        for j in range(depth):\n",
    "            for i in range(self.n_qubits):\n",
    "                qml.RY(weights[j, i], wires=[i])\n",
    "\n",
    "            for i in range(self.n_qubits):\n",
    "                qml.CNOT(wires=[i % self.n_qubits, (i + 1) % self.n_qubits])\n",
    "\n",
    "        return [qml.expval(qml.PauliZ(wires=[i])) for i in range(self.n_qubits)]\n",
    "\n",
    "    def keyCircuit(self, inputs, weights, depth):\n",
    "        return self.queryCircuit(inputs, weights, depth)\n",
    "\n",
    "    def valueCircuit(self, inputs, weights, depth):\n",
    "        return self.queryCircuit(inputs, weights, depth)\n",
    "\n",
    "    def forward_with_pennylane(self, x):\n",
    "        \n",
    "        #x = (B, seq_len, emb_len)\n",
    "        B, T, C = x.shape #save the batch size and sequence length for unflattening\n",
    "        #flatten all batches into one sequence x = (B*seq_len, emb_len) for q_node\n",
    "        x = torch.flatten(x, start_dim=0, end_dim=1)\n",
    "\n",
    "        splitted = torch.split(x, self.n_qubits, dim=-1) #split x into n_parallel chunks each (B*seq_len, n_qubits)\n",
    "        q, k, v = [], [], []\n",
    "        for i in range(self.n_parallel):\n",
    "\n",
    "            q_head = self.query_node(splitted[i], self.query_weights[i], self.qkv_depth[0])\n",
    "            q_head = torch.stack(q_head, dim=-1) # q = (B*seq_len, n_qubit)\n",
    "            q_head = torch.unflatten(q_head, 0, (B, T)) #q = (B, seq_len, n_qubit)\n",
    "            q.append(q_head)\n",
    "\n",
    "            k_head = self.query_node(splitted[i], self.query_weights[i], self.qkv_depth[0])\n",
    "            k_head = torch.stack(k_head, dim=-1) # q = (B*seq_len, n_qubit)\n",
    "            k_head = torch.unflatten(k_head, 0, (B, T)) #q = (B, seq_len, n_qubit)\n",
    "            k.append(k_head)\n",
    "\n",
    "            v_head = self.query_node(splitted[i], self.query_weights[i], self.qkv_depth[0])\n",
    "            v_head = torch.stack(v_head, dim=-1) # q = (B*seq_len, n_qubit)\n",
    "            v_head = torch.unflatten(v_head, 0, (B, T)) #q = (B, seq_len, n_qubit)\n",
    "            v.append(v_head)\n",
    "        \n",
    "        \n",
    "        q = torch.stack(q, dim=1)\n",
    "        k = torch.stack(k, dim=1)\n",
    "        v = torch.stack(v, dim=1)\n",
    "        # q,k,v = (B, n_parallel, T, n_qubit)\n",
    "\n",
    "        att = torch.nn.functional.scaled_dot_product_attention(q, k, v, is_causal=True) #(B, n_parallel, T, n_qubit)\n",
    "        att = att.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        return att\n",
    "\n",
    "    def forward_with_tqml(self, x):\n",
    "        \n",
    "        B, T, C = x.shape\n",
    "        x = torch.flatten(x, start_dim=0, end_dim=1)\n",
    "        \n",
    "        q = self.speedy_query(x)\n",
    "        q = torch.unflatten(q, 0, (B, T)) #q = (B, seq_len, n_qubit)\n",
    "        q = torch.unsqueeze(q, 1)\n",
    "\n",
    "        k = self.speedy_query(x)\n",
    "        k = torch.unflatten(k, 0, (B, T))\n",
    "        k = torch.unsqueeze(k, 1)\n",
    "\n",
    "        v = self.speedy_query(x)\n",
    "        v = torch.unflatten(v, 0, (B, T))\n",
    "        v = torch.unsqueeze(v, 1)\n",
    "\n",
    "        att = torch.nn.functional.scaled_dot_product_attention(q, k, v, is_causal=True) #(B, 1, T, C)\n",
    "        att = torch.squeeze(att)\n",
    "        return att\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "            \n",
    "        if self.speedy:\n",
    "            return self.forward_with_tqml(x)\n",
    "        else:\n",
    "            return self.forward_with_pennylane(x)\n",
    "\n",
    "\n",
    "    def extra_repr(self):\n",
    "        pass\n",
    "\n",
    "    def reset_weights(self):\n",
    "\n",
    "        nn.init.uniform_(self.query_weights, a=0, b=2 * torch.pi)\n",
    "        nn.init.uniform_(self.key_weights, a=0, b=2 * torch.pi)\n",
    "        nn.init.uniform_(self.value_weights, a=0, b=2 * torch.pi)\n",
    "\n",
    "    def draw_circuit(self):\n",
    "        sample_input = torch.randn((self.cfg.d_model,))\n",
    "\n",
    "        query_drawer = qml.draw(self.query_node)\n",
    "        query_diagram = query_drawer(sample_input, self.query_weights, self.qkv_depth[0])\n",
    "\n",
    "        key_drawer = qml.draw(self.key_node)\n",
    "        key_diagram = key_drawer(sample_input, self.key_weights, self.qkv_depth[1])\n",
    "\n",
    "        value_drawer = qml.draw(self.value_node)\n",
    "        value_diagram = value_drawer(sample_input, self.value_weights, self.qkv_depth[2])\n",
    "\n",
    "\n",
    "        print(\"Query circuit:\")\n",
    "        print(query_diagram)\n",
    "        print(\"Key circuit:\")\n",
    "        print(key_diagram)\n",
    "        print(\"Value circuit:\")\n",
    "        print(value_diagram)\n",
    "\n",
    "\n",
    "    def draw_circuit_mpl(self):\n",
    "        # Generate a sample input and weights for visualization\n",
    "        sample_input = torch.randn((self.n_qubits,))\n",
    "\n",
    "        # Use qml.draw_mpl to plot the circuit\n",
    "        qml.draw_mpl(self.query_node)(sample_input, self.weights[0])\n",
    "        plt.title(\"Quantum Circuit\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3_yfxgvtY9m-"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.ln1 = nn.LayerNorm(cfg.d_model, eps=cfg.layer_norm_eps)\n",
    "        self.ln2 = nn.LayerNorm(cfg.d_model, eps=cfg.layer_norm_eps)\n",
    "        self.attn = QAttention(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhalcljNV98n"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Y41-LsvP7nCY"
   },
   "outputs": [],
   "source": [
    "def freeze_and_load(model, reference_model, n_unfreeze=0): #load mlp and ln weights and freeze them except last n blocks\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      #wte and wpe matrices\n",
    "      model.embed.wte.copy_(reference_model.state_dict()['embed.W_E'])\n",
    "      model.embed.wpe.copy_(reference_model.state_dict()['pos_embed.W_pos'])\n",
    "      model.embed.wte.requires_grad_(False)\n",
    "      model.embed.wpe.requires_grad_(False)\n",
    "\n",
    "      #unembedding matrix\n",
    "      model.unembed.unembed.weight.copy_(reference_model.state_dict()['unembed.W_U'].T) #for some strange reason pretrained W_U is transposed\n",
    "      #print(model.unembed.unembed.bias.shape, reference_model.state_dict()['unembed.b_U'].shape)\n",
    "      model.unembed.unembed.bias.copy_(reference_model.state_dict()['unembed.b_U'])\n",
    "      model.unembed.unembed.requires_grad_(False)\n",
    "\n",
    "      #final LayerNorm\n",
    "      model.ln_final.weight.copy_(reference_model.state_dict()['ln_final.w'])\n",
    "      model.ln_final.bias.copy_(reference_model.state_dict()['ln_final.b'])\n",
    "      model.ln_final.requires_grad_(False)\n",
    "\n",
    "      for (n, block) in enumerate(model.blocks):\n",
    "\n",
    "        #LayerNorms\n",
    "        block.ln1.weight.copy_(reference_model.state_dict()['blocks.'+str(n)+'.ln1.w'])\n",
    "        block.ln1.bias.copy_(reference_model.state_dict()['blocks.'+str(n)+'.ln1.b'])\n",
    "        block.ln2.weight.copy_(reference_model.state_dict()['blocks.'+str(n)+'.ln2.w'])\n",
    "        block.ln2.bias.copy_(reference_model.state_dict()['blocks.'+str(n)+'.ln2.b'])\n",
    "        #MLP (the pretrained weights are transposed)\n",
    "        block.mlp.w_in.weight.copy_(reference_model.state_dict()['blocks.'+str(n)+'.mlp.W_in'].T)\n",
    "        block.mlp.w_in.bias.copy_(reference_model.state_dict()['blocks.'+str(n)+'.mlp.b_in'])\n",
    "        block.mlp.w_out.weight.copy_(reference_model.state_dict()['blocks.'+str(n)+'.mlp.W_out'].T)\n",
    "        block.mlp.w_out.bias.copy_(reference_model.state_dict()['blocks.'+str(n)+'.mlp.b_out'])\n",
    "        #freeze weights\n",
    "        if n in range(model.cfg.n_layers-n_unfreeze):\n",
    "          #print(\"weights in block \"+str(n)+\" frozen\")\n",
    "          block.ln1.requires_grad_(False)\n",
    "          block.ln2.requires_grad_(False)\n",
    "          block.mlp.w_in.requires_grad_(False)\n",
    "          block.mlp.w_out.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch_loss, epoch, filename):\n",
    "  torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss_log': epoch_loss,\n",
    "        'epoch': epoch\n",
    "        },\n",
    "        filename\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eADST_JpPDiP"
   },
   "source": [
    "# Full Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bs8rBEGwvsCj"
   },
   "outputs": [],
   "source": [
    "class QGPT(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = nn.LayerNorm(cfg.d_model, eps=cfg.layer_norm_eps)\n",
    "        self.unembed = Unembed(cfg)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        residual = self.embed(tokens)\n",
    "        for block in self.blocks:\n",
    "            residual = block(residual)\n",
    "        logits = self.unembed(self.ln_final(residual))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TdMTjOwV3-XA"
   },
   "outputs": [],
   "source": [
    "qgpt = QGPT(qgpt_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrtDfXfvqub5",
    "outputId": "28874d8c-cb17-4ee3-c888-1536b09c9099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 134904913\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in qgpt.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CUg4ygYkebLL"
   },
   "outputs": [],
   "source": [
    "freeze_and_load(qgpt, reference_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCrbQ-fDqzmo",
    "outputId": "df1aa062-9c88-496e-cade-560f89edacda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 165888\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in qgpt.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLPmmPJGz7Qi",
    "outputId": "3679e0a8-eb32-4c93-e942-54610aa0f168"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QGPT(\n",
       "  (embed): Embed()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): QAttention(\n",
       "        (speedy_query): SpeedyPQN(in_features=768, out_features=768, depth=2, n_qubits=8, embedding_layers=96,measurement_mode=None, rotation=Z, entangling=strong, measure=Y, hw_efficient=False)\n",
       "        (speedy_key): SpeedyPQN(in_features=768, out_features=768, depth=2, n_qubits=8, embedding_layers=96,measurement_mode=None, rotation=Z, entangling=strong, measure=Y, hw_efficient=False)\n",
       "        (speedy_value): SpeedyPQN(in_features=768, out_features=768, depth=2, n_qubits=8, embedding_layers=96,measurement_mode=None, rotation=Z, entangling=strong, measure=Y, hw_efficient=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (w_in): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (w_out): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (unembed): Unembed(\n",
       "    (unembed): Linear(in_features=768, out_features=50257, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qgpt.half()\n",
    "qgpt.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOiAnXX49j9d"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "307ce54f91514a93a887e7a24a6f1045",
      "2dc89e0fb93240638d6954c07e2121e1",
      "5038926bac40436eb48d099b3dbd5125",
      "7172c022ca3e4cfc8528d3bf3dc0ae9a",
      "d5ef620730cf488ea338716b2b82bb9d",
      "7a6114647f10408ca238d82cbf4d242d",
      "eb87aca996a24242b769ad3c5371e13e",
      "8f260ae6dec7408198516538e7acc91e",
      "6bf1020f774c438eb2a3c098621af4a1",
      "2f74d4937fc14086915dd3ef75c95824",
      "31723a0711a448c3b06b92e84fd3c0fa",
      "3aceea12ae9c45dcb1fce9d181e2dc23",
      "9c94c325066841afb3170216007ee4ff",
      "bf1d194c915c40ef912c041bc4805fc1",
      "ac1394fa1343469799af3c3397337c77",
      "4b93553cbcc24d61be75b622571226ed",
      "d523e0412f844598964804ef7418e27e",
      "9fd2a7d314fd4ca49e1e1c2277324f8f",
      "7c3e17b3ca8944fabc204b8cd9f6e16b",
      "40cfb77f9aeb471c822205354d9e3e45",
      "4f988dd781e740e09399d005ec5b2cf9",
      "6a3b8e2c2b72400ba52b23dc77b73e39",
      "87838d03eeab4e6ba0dcec4f78d0d86c",
      "07bcf47c38c447c3b0065e90ca2befbc",
      "84925d1d50254f978e591c8941c2500b",
      "a9714872fabc4796a8c9185259094341",
      "bb84b36b06d14074863457494c7af481",
      "535e2d8ed3df4f7c875b915a1373533c",
      "14cc537383774d009e6bfc05a3fb0436",
      "25971a8ab62a4d4eb3e4b29d4be44af2",
      "291c6c3c048443bd92b440feb8682742",
      "cd8cfd6c5bc3442daf2a44da246f5d29",
      "ddb1cfcd23074728a8a940c29297bad0",
      "d503fb330b534dc18e5e1ce416cb1088",
      "ddf550ab44d8458f9edc91c688ade033",
      "8f86c0465b0e4d74a90e528410b8677b",
      "8a289786d075425fa000052edd519854",
      "c234cc1e3fc9456ca4861e8a180f58b2",
      "60738de59a9f4f2e940b598f6e48f069",
      "10cd6f9a60984e468a2f7722205477fa",
      "55b0a51944f34139886d43712828b5d2",
      "50ad5087051a4ba98cd9e71ed88237a1",
      "72602a90f4b743f4aa5af9fb778e2a8d",
      "2171eb6c565b45d283e0d4d2eb2a2c77"
     ]
    },
    "id": "2Qmw_JGl9mmj",
    "outputId": "e2b4904e-11af-43ad-f21f-9b68ab32fb51"
   },
   "outputs": [],
   "source": [
    "the_pile = load_dataset(\"NeelNanda/pile-10k\", split=\"train\").remove_columns(\"meta\")\n",
    "#wiki = load_dataset(\"NeelNanda/wiki-10k\", split=\"train\")\n",
    "lambada = load_dataset(\"EleutherAI/lambada_openai\")\n",
    "openwebtext = load_dataset(\"Elriggs/openwebtext-100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6021"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(openwebtext['train']['text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rZwHwodVCdQk"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_string, tokenizer, n_ctx):\n",
    "\n",
    "      tokens = tokenizer(text_string)['input_ids']\n",
    "      self.tokens = torch.tensor(tokens)\n",
    "      self.X = torch.stack(torch.split(self.tokens, n_ctx)[:-1])\n",
    "      self.y = torch.stack(torch.split(self.tokens.roll(-1), n_ctx)[:-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Y8j5S8DfQ_XH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3180 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pileDS = TextDataset(the_pile[0]['text'], gpt2_tokenizer, 64)\n",
    "pileDL = DataLoader(pileDS, shuffle=True, pin_memory=True, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambadaDS = TextDataset('.'.join(lambada['test']['text'])[:10000], gpt2_tokenizer, 128)\n",
    "lambadaDL = DataLoader(lambadaDS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "openwebtextDS = TextDataset('.'.join(openwebtext['train']['text'])[:10000], gpt2_tokenizer, 64)\n",
    "openwebtextDL = DataLoader(openwebtextDS, shuffle=True, pin_memory=True, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pseudo model (approximate how much vram we need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.emb = Embed(self.cfg)\n",
    "        self.unemb = Unembed(self.cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.emb(x)\n",
    "        x = self.unemb(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_model = PseudoModel(qgpt_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 78031441\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in pseudo_model.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PseudoModel(\n",
       "  (emb): Embed()\n",
       "  (unemb): Unembed(\n",
       "    (unembed): Linear(in_features=768, out_features=50257, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14, 50257])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_model(text_tokens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPxniAOvrWjU"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "sfJ0Tnpd5WoO"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingArgs:\n",
    "    epochs: int = 30\n",
    "    max_steps_per_epoch: int = 100\n",
    "    lr: int = 0.05\n",
    "    weight_decay: int = 0.01\n",
    "    betas: tuple = (0.9, 0.98)\n",
    "\n",
    "qgpt_training_args = TrainingArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Yja8CFsrYRs"
   },
   "outputs": [],
   "source": [
    "class TransformerTrainer:\n",
    "    def __init__(self, args, model, train_loader, test_loader):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.args = args\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=args.lr, betas=args.betas, weight_decay=args.weight_decay)\n",
    "        self.step = 0\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.metric = Perplexity(ignore_index=-1)\n",
    "\n",
    "\n",
    "    def training_step(self, batch):\n",
    "\n",
    "        #forward pass\n",
    "        tokens, targets = batch\n",
    "        tokens = tokens.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits = self.model(tokens)\n",
    "\n",
    "        #backward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.step += 1\n",
    "\n",
    "        \n",
    "        tokens.detach().cpu()\n",
    "        targets.detach().cpu()\n",
    "        \n",
    "        del tokens, targets, logits, batch\n",
    "        gc.collect()\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "\n",
    "        self.model.eval()\n",
    "        for batch in self.test_loader:\n",
    "            \n",
    "            tokens, targets = batch\n",
    "            tokens.to(device)\n",
    "            targets.to(device)\n",
    "            \n",
    "            logits = self.model(tokens)\n",
    "            self.metric.update(logits.transpose(0, 1), targets.view(-1, 1))\n",
    "\n",
    "            del tokens, targets, logits, batch\n",
    "            gc.collect()\n",
    "            with torch.no_grad():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        return self.metric.compute()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        accuracy = np.nan\n",
    "        log_loss = []\n",
    "\n",
    "        progress_bar = tqdm(total = self.args.max_steps_per_epoch * self.args.epochs)\n",
    "\n",
    "        for epoch in range(self.args.epochs):\n",
    "            batch_loss = 0\n",
    "            for i, batch in enumerate(self.train_loader):\n",
    "\n",
    "                self.model.train()\n",
    "                loss = self.training_step(batch)\n",
    "                batch_loss+=loss.detach().cpu().numpy()\n",
    "                \n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description(f\"Epoch {epoch+1}, loss: {loss:.3f}\")\n",
    "                print(f\"Epoch {epoch+1}, loss: {loss:.3f}\")\n",
    "\n",
    "                #cleanup\n",
    "                \n",
    "                del loss\n",
    "                gc.collect()\n",
    "                with torch.no_grad():\n",
    "                    torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "                \n",
    "            batch_loss /= len(self.train_loader)\n",
    "            log_loss.append(batch_loss)\n",
    "            #print(f\"PPL: {self.test()}\")\n",
    "\n",
    "            save_model(self.model, self.optimizer, log_loss, self.step, \"qgpt100k.pth\")\n",
    "\n",
    "        return log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "referenced_widgets": [
      "5b0bb1f3984b4db4a7245fe1d874f674",
      "b93c1323d3dd4e0babe8fac9df428dc1",
      "71fa0fb00da04483ab2a7f2cf5adc2ed",
      "384ee5e64a5e4b6ab898b081616d82ad",
      "1d2e62c61168428fb0b80e7a19e7cc1e",
      "1bea68566c6b40adace42dec933fb576",
      "54103d74255947698495f346c737ec7c",
      "a84f26024b00485387ef531b644c5701",
      "db47ae23ea6641ddb6cab486d685f7e4",
      "3dad6777f1034683830971f909d19fe9",
      "1770875231eb4ccab3797fbc734ba2fc"
     ]
    },
    "id": "bHmEfC3H0h3A",
    "outputId": "f113acfd-470e-47f2-fe31-a53989a188e6"
   },
   "outputs": [],
   "source": [
    "qgpt_trainer = TransformerTrainer(qgpt_training_args, qgpt, openwebtextDL, lambadaDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_log = qgpt_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"409.426007pt\" height=\"310.86825pt\" viewBox=\"0 0 409.426007 310.86825\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-12-13T07:52:51.858421</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 310.86825 \n",
       "L 409.426007 310.86825 \n",
       "L 409.426007 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 273.312 \n",
       "L 400.90125 273.312 \n",
       "L 400.90125 7.2 \n",
       "L 43.78125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m29dfee7893\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m29dfee7893\" x=\"60.013977\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(56.832727 287.910438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m29dfee7893\" x=\"115.988899\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(112.807649 287.910438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m29dfee7893\" x=\"171.963821\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(165.601321 287.910438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m29dfee7893\" x=\"227.938742\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(221.576242 287.910438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m29dfee7893\" x=\"283.913664\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(277.551164 287.910438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m29dfee7893\" x=\"339.888585\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(333.526085 287.910438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m29dfee7893\" x=\"395.863507\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(389.501007 287.910438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(207.113125 301.588562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <defs>\n",
       "       <path id=\"m2d8a1e7027\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2d8a1e7027\" x=\"43.78125\" y=\"240.420439\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 4.8 -->\n",
       "      <g transform=\"translate(20.878125 244.219658) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2d8a1e7027\" x=\"43.78125\" y=\"206.770684\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 5.0 -->\n",
       "      <g transform=\"translate(20.878125 210.569903) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2d8a1e7027\" x=\"43.78125\" y=\"173.120929\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 5.2 -->\n",
       "      <g transform=\"translate(20.878125 176.920148) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2d8a1e7027\" x=\"43.78125\" y=\"139.471175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 5.4 -->\n",
       "      <g transform=\"translate(20.878125 143.270393) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2d8a1e7027\" x=\"43.78125\" y=\"105.82142\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 5.6 -->\n",
       "      <g transform=\"translate(20.878125 109.620639) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2d8a1e7027\" x=\"43.78125\" y=\"72.171665\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 5.8 -->\n",
       "      <g transform=\"translate(20.878125 75.970884) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2d8a1e7027\" x=\"43.78125\" y=\"38.52191\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 6.0 -->\n",
       "      <g transform=\"translate(20.878125 42.321129) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Cross-entropy loss -->\n",
       "     <g transform=\"translate(14.798438 186.351313) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"69.824219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"108.6875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"169.869141\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"221.96875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2d\" x=\"274.068359\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"310.152344\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"371.675781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"435.054688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"474.263672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"513.126953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"574.308594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"637.785156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"696.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"728.751953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"756.535156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"817.716797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"869.816406\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 60.013977 19.296 \n",
       "L 71.208962 114.456887 \n",
       "L 82.403946 150.850441 \n",
       "L 93.59893 168.966611 \n",
       "L 104.793915 192.359642 \n",
       "L 115.988899 194.824137 \n",
       "L 127.183883 200.377607 \n",
       "L 138.378868 210.678766 \n",
       "L 149.573852 218.933984 \n",
       "L 160.768836 222.980567 \n",
       "L 171.963821 226.228466 \n",
       "L 183.158805 228.173488 \n",
       "L 194.353789 229.990111 \n",
       "L 205.548774 236.033259 \n",
       "L 216.743758 243.476832 \n",
       "L 227.938742 247.626194 \n",
       "L 239.133726 246.854553 \n",
       "L 250.328711 249.28288 \n",
       "L 261.523695 253.243977 \n",
       "L 272.718679 255.420433 \n",
       "L 283.913664 249.706407 \n",
       "L 295.108648 249.95261 \n",
       "L 306.303632 255.475367 \n",
       "L 317.498617 254.022232 \n",
       "L 328.693601 251.153349 \n",
       "L 339.888585 253.732948 \n",
       "L 351.08357 258.852505 \n",
       "L 362.278554 257.838906 \n",
       "L 373.473538 259.150797 \n",
       "L 384.668523 261.216 \n",
       "\" clip-path=\"url(#pfc0d00f685)\" style=\"fill: none; stroke: #ffa500; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 273.312 \n",
       "L 43.78125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 400.90125 273.312 \n",
       "L 400.90125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 273.312 \n",
       "L 400.90125 273.312 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 7.2 \n",
       "L 400.90125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pfc0d00f685\">\n",
       "   <rect x=\"43.78125\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(qgpt_training_args.epochs), loss_log, color='orange')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Cross-entropy loss\")\n",
    "\n",
    "plt.savefig('100k_loss.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5md_-gpd-vy"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "IUYV21O3WHTc"
   },
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "\n",
    "    def __init__(self, cfg, model, tokenizer):\n",
    "\n",
    "      self.cfg = cfg\n",
    "      self.model = model\n",
    "      self.tokenizer = tokenizer\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(self, tokens, n_new_tokens, temperature=1.0, top_k=None):\n",
    "\n",
    "        for _ in range(n_new_tokens):\n",
    "            #crop sequence at context size if required\n",
    "            cropped_tokens = tokens if tokens.size(1) <= self.cfg.n_ctx else tokens[:, -self.cfg.n_ctx:]\n",
    "            #forward the model\n",
    "            logits = self.model(cropped_tokens)\n",
    "            #get the last logit and scale it by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            #apply top k\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            #softmax\n",
    "            probs = nn.functional.softmax(logits, dim=-1)\n",
    "            #sample nect tokens\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            #add the sample token to the sequence\n",
    "            tokens = torch.cat((tokens, next_token), dim=1)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def sample(self, tokens, n_new_tokens, temperature=1, top_k=None):\n",
    "\n",
    "        sentences = []\n",
    "        token_sequences = self.generate(tokens, n_new_tokens, temperature, top_k)\n",
    "        for sequence in token_sequences:\n",
    "            sentence = self.tokenizer.decode(sequence)\n",
    "            sentences.append(sentence)\n",
    "\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ijByXuB3eAoG"
   },
   "outputs": [],
   "source": [
    "qgpt_sampler = Sampler(qgpt_cfg, qgpt, gpt2_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gaYNeJDyeXva"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>Jingle bells, jingle bells, jingle all the way through the Republican candidate for the security for the delegates',\n",
       " '<|endoftext|>Today I was walking home, when suddenly<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\"We have seen an investigation, but that the']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgpt_sampler.sample(text_tokens, 10, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsyRLOs3j0ur"
   },
   "outputs": [],
   "source": [
    "gpt2_sampler = Sampler(qgpt_cfg, reference_gpt2, gpt2_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-I7sVqOkJb8"
   },
   "outputs": [],
   "source": [
    "qgpt_sampler.sample(text_tokens, 10, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(qgpt.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as in the trainer class, better use it from there, this is a temporary solution\n",
    "def test(model, test_loader):\n",
    "\n",
    "    metric = Perplexity(ignore_index=-1).to(device)\n",
    "    model.eval()\n",
    "    for batch in test_loader:\n",
    "        \n",
    "        tokens, targets = batch\n",
    "        tokens.to(device)\n",
    "        targets.to(device)\n",
    "        logits = model(tokens)\n",
    "        metric.update(logits.transpose(0, 1), targets.view(-1, 1))\n",
    "\n",
    "        del tokens, targets, logits, batch\n",
    "        gc.collect()\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    return metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(422.0023, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(qgpt, lambadaDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QGPT(\n",
       "  (embed): Embed()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): QAttention(\n",
       "        (speedy_query): SpeedyPQN(in_features=768, out_features=8, depth=2, n_qubits=8, embedding_layers=96,measurement_mode=None, rotation=Z, entangling=strong, measure=Y, hw_efficient=False)\n",
       "        (speedy_key): SpeedyPQN(in_features=768, out_features=768, depth=2, n_qubits=8, embedding_layers=96,measurement_mode=None, rotation=Z, entangling=strong, measure=Y, hw_efficient=False)\n",
       "        (speedy_value): SpeedyPQN(in_features=768, out_features=768, depth=2, n_qubits=8, embedding_layers=96,measurement_mode=None, rotation=Z, entangling=strong, measure=Y, hw_efficient=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (w_in): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (w_out): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (unembed): Unembed(\n",
       "    (unembed): Linear(in_features=768, out_features=50257, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgpt.to('cpu')\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "qgpt.to(device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07bcf47c38c447c3b0065e90ca2befbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_535e2d8ed3df4f7c875b915a1373533c",
      "placeholder": "",
      "style": "IPY_MODEL_14cc537383774d009e6bfc05a3fb0436",
      "value": "()-00000-of-00001-4746b8785c874cc7.parquet:100%"
     }
    },
    "10cd6f9a60984e468a2f7722205477fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14cc537383774d009e6bfc05a3fb0436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1770875231eb4ccab3797fbc734ba2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bea68566c6b40adace42dec933fb576": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d2e62c61168428fb0b80e7a19e7cc1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2171eb6c565b45d283e0d4d2eb2a2c77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25971a8ab62a4d4eb3e4b29d4be44af2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "291c6c3c048443bd92b440feb8682742": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2dc89e0fb93240638d6954c07e2121e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a6114647f10408ca238d82cbf4d242d",
      "placeholder": "",
      "style": "IPY_MODEL_eb87aca996a24242b769ad3c5371e13e",
      "value": "README.md:100%"
     }
    },
    "2f74d4937fc14086915dd3ef75c95824": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "307ce54f91514a93a887e7a24a6f1045": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2dc89e0fb93240638d6954c07e2121e1",
       "IPY_MODEL_5038926bac40436eb48d099b3dbd5125",
       "IPY_MODEL_7172c022ca3e4cfc8528d3bf3dc0ae9a"
      ],
      "layout": "IPY_MODEL_d5ef620730cf488ea338716b2b82bb9d"
     }
    },
    "31723a0711a448c3b06b92e84fd3c0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "384ee5e64a5e4b6ab898b081616d82ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dad6777f1034683830971f909d19fe9",
      "placeholder": "",
      "style": "IPY_MODEL_1770875231eb4ccab3797fbc734ba2fc",
      "value": "1/1000[1:44:50&lt;1745:39:31,6290.66s/it]"
     }
    },
    "3aceea12ae9c45dcb1fce9d181e2dc23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c94c325066841afb3170216007ee4ff",
       "IPY_MODEL_bf1d194c915c40ef912c041bc4805fc1",
       "IPY_MODEL_ac1394fa1343469799af3c3397337c77"
      ],
      "layout": "IPY_MODEL_4b93553cbcc24d61be75b622571226ed"
     }
    },
    "3dad6777f1034683830971f909d19fe9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40cfb77f9aeb471c822205354d9e3e45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b93553cbcc24d61be75b622571226ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f988dd781e740e09399d005ec5b2cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5038926bac40436eb48d099b3dbd5125": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f260ae6dec7408198516538e7acc91e",
      "max": 373,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6bf1020f774c438eb2a3c098621af4a1",
      "value": 373
     }
    },
    "50ad5087051a4ba98cd9e71ed88237a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "535e2d8ed3df4f7c875b915a1373533c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54103d74255947698495f346c737ec7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55b0a51944f34139886d43712828b5d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b0bb1f3984b4db4a7245fe1d874f674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b93c1323d3dd4e0babe8fac9df428dc1",
       "IPY_MODEL_71fa0fb00da04483ab2a7f2cf5adc2ed",
       "IPY_MODEL_384ee5e64a5e4b6ab898b081616d82ad"
      ],
      "layout": "IPY_MODEL_1d2e62c61168428fb0b80e7a19e7cc1e"
     }
    },
    "60738de59a9f4f2e940b598f6e48f069": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a3b8e2c2b72400ba52b23dc77b73e39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bf1020f774c438eb2a3c098621af4a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7172c022ca3e4cfc8528d3bf3dc0ae9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f74d4937fc14086915dd3ef75c95824",
      "placeholder": "",
      "style": "IPY_MODEL_31723a0711a448c3b06b92e84fd3c0fa",
      "value": "373/373[00:00&lt;00:00,8.14kB/s]"
     }
    },
    "71fa0fb00da04483ab2a7f2cf5adc2ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a84f26024b00485387ef531b644c5701",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db47ae23ea6641ddb6cab486d685f7e4",
      "value": 1
     }
    },
    "72602a90f4b743f4aa5af9fb778e2a8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a6114647f10408ca238d82cbf4d242d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c3e17b3ca8944fabc204b8cd9f6e16b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84925d1d50254f978e591c8941c2500b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25971a8ab62a4d4eb3e4b29d4be44af2",
      "max": 33262901,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_291c6c3c048443bd92b440feb8682742",
      "value": 33262901
     }
    },
    "87838d03eeab4e6ba0dcec4f78d0d86c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_07bcf47c38c447c3b0065e90ca2befbc",
       "IPY_MODEL_84925d1d50254f978e591c8941c2500b",
       "IPY_MODEL_a9714872fabc4796a8c9185259094341"
      ],
      "layout": "IPY_MODEL_bb84b36b06d14074863457494c7af481"
     }
    },
    "8a289786d075425fa000052edd519854": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72602a90f4b743f4aa5af9fb778e2a8d",
      "placeholder": "",
      "style": "IPY_MODEL_2171eb6c565b45d283e0d4d2eb2a2c77",
      "value": "10000/10000[00:01&lt;00:00,9126.90examples/s]"
     }
    },
    "8f260ae6dec7408198516538e7acc91e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f86c0465b0e4d74a90e528410b8677b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55b0a51944f34139886d43712828b5d2",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50ad5087051a4ba98cd9e71ed88237a1",
      "value": 10000
     }
    },
    "9c94c325066841afb3170216007ee4ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d523e0412f844598964804ef7418e27e",
      "placeholder": "",
      "style": "IPY_MODEL_9fd2a7d314fd4ca49e1e1c2277324f8f",
      "value": "dataset_infos.json:100%"
     }
    },
    "9fd2a7d314fd4ca49e1e1c2277324f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a84f26024b00485387ef531b644c5701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9714872fabc4796a8c9185259094341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd8cfd6c5bc3442daf2a44da246f5d29",
      "placeholder": "",
      "style": "IPY_MODEL_ddb1cfcd23074728a8a940c29297bad0",
      "value": "33.3M/33.3M[00:00&lt;00:00,145MB/s]"
     }
    },
    "ac1394fa1343469799af3c3397337c77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f988dd781e740e09399d005ec5b2cf9",
      "placeholder": "",
      "style": "IPY_MODEL_6a3b8e2c2b72400ba52b23dc77b73e39",
      "value": "921/921[00:00&lt;00:00,39.8kB/s]"
     }
    },
    "b93c1323d3dd4e0babe8fac9df428dc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bea68566c6b40adace42dec933fb576",
      "placeholder": "",
      "style": "IPY_MODEL_54103d74255947698495f346c737ec7c",
      "value": "Epoch1,loss:6.719,accuracy:nan:0%"
     }
    },
    "bb84b36b06d14074863457494c7af481": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf1d194c915c40ef912c041bc4805fc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c3e17b3ca8944fabc204b8cd9f6e16b",
      "max": 921,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40cfb77f9aeb471c822205354d9e3e45",
      "value": 921
     }
    },
    "c234cc1e3fc9456ca4861e8a180f58b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd8cfd6c5bc3442daf2a44da246f5d29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d503fb330b534dc18e5e1ce416cb1088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddf550ab44d8458f9edc91c688ade033",
       "IPY_MODEL_8f86c0465b0e4d74a90e528410b8677b",
       "IPY_MODEL_8a289786d075425fa000052edd519854"
      ],
      "layout": "IPY_MODEL_c234cc1e3fc9456ca4861e8a180f58b2"
     }
    },
    "d523e0412f844598964804ef7418e27e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5ef620730cf488ea338716b2b82bb9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db47ae23ea6641ddb6cab486d685f7e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ddb1cfcd23074728a8a940c29297bad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddf550ab44d8458f9edc91c688ade033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60738de59a9f4f2e940b598f6e48f069",
      "placeholder": "",
      "style": "IPY_MODEL_10cd6f9a60984e468a2f7722205477fa",
      "value": "Generatingtrainsplit:100%"
     }
    },
    "eb87aca996a24242b769ad3c5371e13e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
